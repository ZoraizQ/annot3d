# -*- coding: utf-8 -*-
"""neurodl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DIWMDnPfx__uAxny0b66kKcg_TjYLR_Z
"""

from __future__ import print_function
from keras.preprocessing.image import ImageDataGenerator
import numpy as np 
import os
import skimage.io as io
import skimage.transform as trans
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras import backend as keras
import tensorflow.image as tfimage
import matplotlib.pyplot as plt
import matplotlib.image as mpimg 

train_path = ''
train_image_folder = 'image'
train_label_folder = 'label'
test_label_path = 'test_label'
test_path = 'test'
model_name = "unet_neurons.hdf5"
train_image_path = os.path.join(train_path, train_image_folder)
train_label_path = os.path.join(train_path, train_label_folder)

# !rm -rf /content/*

# only download the zip file if it does not exist and unzip if image folder does not exist
#![ ! -f /content/neurons_xz.zip ] && gdown https://drive.google.com/uc?id=1EG4VrEeNQaUd4tkdtewIDx37AS9ODBpm
#![ ! -d /content/image ] &&  unzip /content/neurons_xz.zip

# ![ ! -f /content/neurons_xy.zip ] && gdown https://drive.google.com/uc?id=1189IRA4l8y-hCkCIlI93pjU8mB8CAoye
# ![ ! -d /content/image ] && unzip /content/neurons_xy.zip

test_samples = 25
target_size_init = (32, 640)
input_size_init = (32, 640, 1)

# test_samples = 5
# target_size_init = (512, 512)
# input_size_init = (512, 512, 1)

original_size = mpimg.imread(os.path.join(train_image_path,'0.png')).shape # get shape from 1 image from training set

if not os.path.exists(test_path):
    os.mkdir(test_path)
    os.mkdir(test_label_path)
    _, _, filenames = next(os.walk(train_image_path))
    for i in range(test_samples-1,-1,-1):
        filename = str(len(filenames)-1-i) + ".png"
        os.rename(os.path.join(train_image_path,filename),os.path.join(test_path,str(test_samples-1-i)+".png"))
        os.rename(os.path.join(train_label_path,filename),os.path.join(test_label_path,str(test_samples-1-i)+".png"))

img = mpimg.imread(os.path.join(train_image_path,'10.png'))
img_label = mpimg.imread(os.path.join(train_label_path,'10.png'))
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,8))
ax1.imshow(img)
ax2.imshow(img_label)
print(original_size)

MASK_COLOR = [0,0,0]

def normalize(img):
    min = img.min()
    max = img.max()
    x = 2.0 * (img - min) / (max - min) - 1.0
    return x

def adjustData(img,mask):
    if(np.max(img) > 1):
        img = normalize(img)
        mask = mask / 255 # mask is 8 bit
        mask[mask > 0.5] = 1
        mask[mask <= 0.5] = 0
    return (img,mask)


def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = "grayscale",
                    mask_color_mode = "grayscale", image_save_prefix  = "image", mask_save_prefix  = "mask",
                    save_to_dir = None, target_size = original_size, seed = 1): # keep it to the same original size but pad
    '''
    can generate image and mask at the same time
    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same
    if you want to visualize the results of generator, set save_to_dir = "your path"
    '''
    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)
    image_generator = image_datagen.flow_from_directory(
        train_path,
        classes = [image_folder],
        class_mode = None,
        color_mode = image_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = image_save_prefix,
        seed = seed)
    mask_generator = mask_datagen.flow_from_directory(
        train_path,
        classes = [mask_folder],
        class_mode = None,
        color_mode = mask_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = mask_save_prefix,
        seed = seed)
    train_generator = zip(image_generator, mask_generator)
    for (img,mask) in train_generator:
        img,mask = adjustData(img,mask)

        # padding to target size
        # print(img.shape, mask.shape)
        img = tfimage.pad_to_bounding_box(image=img, offset_height=0, offset_width=0, target_height=target_size_init[0], target_width=target_size_init[1])
        mask = tfimage.pad_to_bounding_box(image=mask, offset_height=0, offset_width=0, target_height=target_size_init[0], target_width=target_size_init[1])
        

        yield (img,mask)



def testGenerator(test_path, num_image = 5, target_size = target_size_init, as_gray = True):
    for i in range(num_image):
        img = io.imread(os.path.join(test_path,"%d.png"%i),as_gray = as_gray)
        img = normalize(img)
        # resize to target size
        # img = trans.resize(img,target_size)

        img = np.reshape(img,img.shape+(1,)) # (x,y) -> (x,y,1) added dimension
        
        # padding instead
        img = tfimage.pad_to_bounding_box(image=img, offset_height=0, offset_width=0, target_height=target_size_init[0], target_width=target_size_init[1])
        
        img = np.reshape(img,(1,)+img.shape) # (x,y,1) -> (1,x,y,1)
        yield img


def geneTrainNpy(image_path,mask_path,image_prefix = "image",mask_prefix = "mask",image_as_gray = True,mask_as_gray = True):
    image_name_arr = glob.glob(os.path.join(image_path,"%s*.png"%image_prefix))
    image_arr = []
    mask_arr = []
    for index,item in enumerate(image_name_arr):
        img = io.imread(item,as_gray = image_as_gray)
        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img
        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)
        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask
        img,mask = adjustData(img,mask)
        image_arr.append(img)
        mask_arr.append(mask)
    image_arr = np.array(image_arr)
    mask_arr = np.array(mask_arr)
    return image_arr,mask_arr


def getResults(save_path, npyfile, save=True):
    img_results = []
    for i,item in enumerate(npyfile):
        img = item[:,:,0] * 255
        img_results.append(img)
        if save:
            io.imsave(os.path.join(save_path,"%d_predict.png"%i),img.astype(np.uint8)) # 8bit png prediction
    return img_results

def unet(pretrained_weights = None,input_size = input_size_init):
    inputs = Input(input_size)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    model = Model(inputs = inputs, outputs = conv10)

    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
    
    # model.summary()

    if(pretrained_weights):
    	model.load_weights(pretrained_weights)

    return model

"""## Train your Unet with neurons data
The input shape of image and mask are the same :(batch_size, rows, cols, channel = 1)
"""

if not os.path.exists(os.path.join(train_path, model_name)):
    # data_gen_args = dict()
    data_gen_args = dict(rotation_range=0.2,
                        width_shift_range=0.05,
                        height_shift_range=0.05,
                        shear_range=0.05,
                        zoom_range=0.05,
                        horizontal_flip=True,
                        fill_mode='nearest')
    trainGen = trainGenerator(2, train_path, train_image_folder, train_label_folder, data_gen_args, save_to_dir=None)
    model = unet()
    model_checkpoint = ModelCheckpoint(model_name, monitor='loss',verbose=1, save_best_only=True)
    model.fit(trainGen, steps_per_epoch=300, epochs=4, callbacks=[model_checkpoint])
else:
    print(f'Trained model already exists: {model_name}')

"""### Test your model and save predicted results"""

testGen = testGenerator(test_path, num_image=test_samples)
model = unet()
model.load_weights(model_name)

np_results = model.predict(testGen, verbose=1)
img_results = getResults(test_path, np_results, save=True)

print(img_results[0].shape)
print('Prediction, Thresholded & Resized/Cropped Prediction, Source, Annotation')
for i in range(25):
    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(18,6))
    pred_img = img_results[i]
    ax1.imshow(pred_img)
    pred_img[pred_img > 150] = 255 # basic thresholding
    # pred_img = trans.resize(pred_img, original_size) # resize to original size
    pred_img = pred_img[:original_size[0], :original_size[1]] # cropped padded image result
    ax2.imshow(pred_img)
    ax3.imshow(mpimg.imread(os.path.join(test_path,str(i)+'.png')))
    ax4.imshow(mpimg.imread(os.path.join(test_label_path,str(i)+'.png')))

img = io.imread(os.path.join("image/0.png"),as_gray=True)
img = normalize(img)
img = np.reshape(img,img.shape+(1,))
img = tfimage.pad_to_bounding_box(img, 0, 0, target_size_init[0], target_size_init[1])
img = np.reshape(img,(1,)+img.shape) # (x,y,1) -> (1,x,y,1)

t = 0.7 # thresholding param
print("Threshold =",t)

np_results = model.predict(img, verbose=1)
pred = np_results[0]
output = pred[:,:,0]
pred = pred.reshape(pred.shape[0], pred.shape[1])

print("Output")
plt.figure()
plt.imshow(output)
plt.show()

bin_pred = np.copy(pred)
bin_pred = np.where(bin_pred < t, 1, 0) # transparent if above threshold else annotation
bin_pred = bin_pred[:25, :500]

rgba_pred = np.stack((bin_pred,)*4, axis=-1)
rgba_pred = np.where(rgba_pred == [1,1,1,1], [255,0,0,255], [0,0,0,0]) #color for rgba else transparent

print("RGBA Prediction")
plt.figure()
plt.imshow(rgba_pred)
plt.show()

print("Annotation")
plt.figure()
plt.imshow(mpimg.imread(os.path.join("label/0.png")))
plt.show()

print("Source")
plt.figure()
plt.imshow(mpimg.imread(os.path.join("image/0.png")))
plt.show()
